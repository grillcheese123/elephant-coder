{"ts": "2026-02-09T00:39:56Z", "session_id": "full_prompt_parity_20260209a_test_02_baseline_r1", "role": "user", "command": "/code", "run_id": "run_1ccade1ba3e7", "content": "Write tests for model retry and fallback telemetry in /code responses."}
{"ts": "2026-02-09T00:39:56Z", "session_id": "full_prompt_parity_20260209a_test_02_baseline_r1", "role": "assistant", "command": "/code", "run_id": "run_1ccade1ba3e7", "content": "{\"summary\":\"Write tests for model retry and fallback telemetry in /code responses.\",\"project\":{\"language\":\"python\"},\"files\":[{\"path\":\"tests/test_model_retry_fallback.py\",\"content\":\"\\\"\\\"\\\"Tests for model retry and fallback telemetry in /code responses.\\\"\\\"\\\"\\n\\nfrom __future__ import annotations\\n\\nimport importlib.util\\nimport sys\\nfrom pathlib import Path\\n\\n\\ndef _load_cli_module():\\n    root = Path(__file__).resolve().parents[1]\\n    cli_path = root / \\\"scripts\\\" / \\\"elephant_cli.py\\\"\\n    spec = importlib.util.spec_from_file_location(\\\"elephant_cli_local\\\", cli_path)\\n    if spec is None or spec.loader is None:\\n        raise RuntimeError(\\\"Unable to load scripts/elephant_cli.py\\\")\\n    module = importlib.util.module_from_spec(spec)\\n    sys.modules[spec.name] = module\\n    spec.loader.exec_module(module)\\n    return module\\n\\n\\nelephant_cli = _load_cli_module()\\n\\n\\ndef test_retry_fallback_telemetry_on_retryable_error(tmp_path: Path, monkeypatch):\\n    \\\"\\\"\\\"Verify telemetry records retry attempts and fallback selection on retryable errors.\\\"\\\"\\\"\\n    (tmp_path / \\\"pyproject.toml\\\").write_text(\\\"[project]\\\\nname='tmp'\\\\n\\\", encoding=\\\"utf-8\\\")\\n    monkeypatch.setenv(\\\"ELEPHANT_PROJECT_ROOT\\\", str(tmp_path))\\n\\n    # Simulate retryable errors for first two models, success on fallback\\n    original_chat = elephant_cli.OpenRouterClient.chat_completion\\n\\n    call_tracker = {\\\"attempts\\\": 0, \\\"models\\\": []}\\n\\n    def mock_chat_completion(self, *, model, messages, max_tokens, temperature=0.2, timeout_sec=60):\\n        call_tracker[\\\"attempts\\\"] += 1\\n        call_tracker[\\\"models\\\"].append(model)\\n        if call_tracker[\\\"attempts\\\"] <= 2:\\n            raise elephant_cli.OpenRouterError(\\\"HTTP 429: Rate limit exceeded\\\")\\n        return elephant_cli.OpenRouterResult(\\n            content='{\\\"plan_steps\\\":[],\\\"cot_steps\\\":[]}',\\n            usage={\\\"prompt_tokens\\\": 10, \\\"completion_tokens\\\": 10, \\\"total_tokens\\\": 20},\\n            estimated_cost_usd=0.001,\\n            raw={\\\"choices\\\": [{\\\"message\\\": {\\\"content\\\": '{\\\"plan_steps\\\":[],\\\"cot_steps\\\":[]}'}}], \\\"usage\\\": {\\\"prompt_tokens\\\": 10, \\\"completion_tokens\\\": 10, \\\"total_tokens\\\": 20}},\\n        )\\n\\n    monkeypatch.setattr(elephant_cli.OpenRouterClient, \\\"chat_completion\\\", mock_chat_completion)\\n\\n    args = elephant_cli._parse([\\\"code\\\", \\\"--cwd\\\", str(tmp_path), \\\"--task\\\", \\\"add feature\\\", \\\"--output\\\", \\\"json\\\"])\\n    code, response = elephant_cli.execute_command(args)\\n\\n    assert code == 0\\n    assert response[\\\"ok\\\"] is True\\n    assert call_tracker[\\\"attempts\\\"] == 3\\n    assert call_tracker[\\\"models\\\"][0] == \\\"gpt-4o-mini\\\"\\n    assert call_tracker[\\\"models\\\"][1] == \\\"gpt-4o\\\"\\n    assert call_tracker[\\\"models\\\"][2] == \\\"claude-3-5-sonnet-20241022\\\"\\n    assert response[\\\"metrics\\\"][\\\"model_retries\\\"] == 2\\n    assert response[\\\"metrics\\\"][\\\"model_fallbacks\\\"] == [\\\"gpt-4o\\\", \\\"claude-3-5-sonnet-20241022\\\"]\\n\\n\\ndef test_retry_fallback_telemetry_on_fatal_error(tmp_path: Path, monkeypatch):\\n    \\\"\\\"\\\"Verify telemetry stops retrying on fatal errors and records them.\\\"\\\"\\\"\\n    (tmp_path / \\\"pyproject.toml\\\").write_text(\\\"[project]\\\\nname='tmp'\\\\n\\\", encoding=\\\"utf-8\\\")\\n    monkeypatch.setenv(\\\"ELEPHANT_PROJECT_ROOT\\\", str(tmp_path))\\n\\n    original_chat = elephant_cli.OpenRouterClient.chat_completion\\n\\n    call_tracker = {\\\"attempts\\\": 0}\\n\\n    def mock_chat_completion(self, *, model, messages, max_tokens, temperature=0.2, timeout_sec=60):\\n        call_tracker[\\\"attempts\\\"] += 1\\n        raise elephant_cli.OpenRouterError(\\\"HTTP 401: Invalid API key\\\")\\n\\n    monkeypatch.setattr(elephant_cli.OpenRouterClient, \\\"chat_completion\\\", mock_chat_completion)\\n\\n    args = elephant_cli._parse([\\\"code\\\", \\\"--cwd\\\", str(tmp_path), \\\"--task\\\", \\\"add feature\\\", \\\"--output\\\", \\\"json\\\"])\\n    code, response = elephant_cli.execute_command(args)\\n\\n    assert code != 0\\n    assert response[\\\"ok\\\"] is False\\n    assert call_tracker[\\\"attempts\\\"] == 1  # No retries on fatal error\\n    assert response[\\\"metrics\\\"][\\\"model_retries\\\"] == 0\\n    assert response[\\\"metrics\\\"][\\\"model_fallbacks\\\"] == []\\n\\n\\ndef test_retry_fallback_telemetry_no_retry_needed(tmp_path: Path, monkeypatch):\\n    \\\"\\\"\\\"Verify telemetry reports zero retries when first model succeeds.\\\"\\\"\\\"\\n    (tmp_path / \\\"pyproject.toml\\\").write_text(\\\"[project]\\\\nname='tmp'\\\\n\\\", encoding=\\\"utf-8\\\")\\n    monkeypatch.setenv(\\\"ELEPHANT_PROJECT_ROOT\\\", str(tmp_path))\\n\\n    def mock_chat_completion(self, *, model, messages, max_tokens, temperature=0.2, timeout_sec=60):\\n        return elephant_cli.OpenRouterResult(\\n            content='{\\\"plan_steps\\\":[],\\\"cot_steps\\\":[]}',\\n            usage={\\\"prompt_tokens\\\": 10, \\\"completion_tokens\\\": 10, \\\"total_tokens\\\": 20},\\n            estimated_cost_usd=0.001,\\n            raw={\\\"choices\\\": [{\\\"message\\\": {\\\"content\\\": '{\\\"plan_steps\\\":[],\\\"cot_steps\\\":[]}'}}], \\\"usage\\\": {\\\"prompt_tokens\\\": 10, \\\"completion_tokens\\\": 10, \\\"total_tokens\\\": 20}},\\n        )\\n\\n    monkeypatch.setattr(elephant_cli.OpenRouterClient, \\\"chat_completion\\\", mock_chat_completion)\\n\\n    args = elephant_cli._parse([\\\"code\\\", \\\"--cwd\\\", str(tmp_path), \\\"--task\\\", \\\"add feature\\\", \\\"--output\\\", \\\"json\\\"])\\n    code, response = elephant_cli.execute_command(args)\\n\\n    assert code == 0\\n    assert response[\\\"ok\\\"] is True\\n    assert response[\\\"metrics\\\"][\\\"model_retries\\\"] == 0\\n    assert response[\\\"metrics\\\"][\\\"model_fallbacks\\\"] == []\\n\\n\\ndef test_is_retryable_model_error():\\n    \\\"\\\"\\\"Verify retryable error classification.\\\"\\\"\\\"\\n    assert elephant_cli._is_retryable_model_error(\\\"HTTP 429: Rate limit exceeded\\\") is True\\n    assert elephant_cli._is_retryable_model_error(\\\"HTTP 504: Gateway timeout\\\") is True\\n    assert elephant_cli._is_retryable_model_error(\\\"Network error: Connection refused\\\") is True\\n    assert elephant_cli._is_retryable_model_error(\\\"HTTP 401: Invalid API key\\\") is False\\n    assert elephant_cli._is_retryable_model_error(\\\"HTTP 400: Bad request\\\") is False\\n\\n\\ndef test_is_fatal_model_error():\\n    \\\"\\\"\\\"Verify fatal error classification.\\\"\\\"\\\"\\n    assert elephant_cli._is_fatal_model_error(\\\"HTTP 401: Invalid API key\\\") is True\\n    assert elephant_cli._is_fatal_model_error(\\\"HTTP 400: Bad request\\\") is True\\n    assert elephant_cli._is_fatal_model_error(\\\"HTTP 429: Rate limit exceeded\\\") is False\\n    assert elephant_cli._is_fatal_model_error(\\\"HTTP 504: Gateway timeout\\\") is False\\n\"}],\"dependencies\":{\"dependencies\":{},\"devDependencies\":{},\"python\":[\"pytest==8.3.4\"],\"pythonDev\":[\"pytest==8.3.4\"],\"rust\":[],\"go\":[],\"cpp\":[]},\"commands\":[\"pytest tests/test_model_retry_fallback.py -v\"]}"}
