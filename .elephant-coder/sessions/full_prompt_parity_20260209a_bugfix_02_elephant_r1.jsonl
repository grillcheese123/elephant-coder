{"ts": "2026-02-09T00:28:40Z", "session_id": "full_prompt_parity_20260209a_bugfix_02_elephant_r1", "role": "user", "command": "/code", "run_id": "run_20f23cb1d05b", "content": "Fix stats aggregation to handle malformed run records without crashing."}
{"ts": "2026-02-09T00:28:40Z", "session_id": "full_prompt_parity_20260209a_bugfix_02_elephant_r1", "role": "assistant", "command": "/code", "run_id": "run_20f23cb1d05b", "content": "```json\n{\n  \"summary\": \"Fix stats aggregation to handle malformed run records without crashing.\",\n  \"project\": {\n    \"language\": \"python\"\n  },\n  \"files\": [\n    {\n      \"path\": \"scripts/elephant_cli.py\",\n      \"content\": \"def _collect_reliability_metrics(run_payloads: list[dict[str, Any]]) -> dict[str, Any]:\\n    if not run_payloads:\\n        return {\\n            \\\"runs_total\\\": 0,\\n            \\\"success_rate\\\": 0.0,\\n            \\\"avg_total_tokens\\\": 0,\\n            \\\"avg_latency_ms\\\": 0,\\n            \\\"total_cost_usd\\\": 0.0,\\n        }\\n\\n    valid_runs = []\\n    for run in run_payloads:\\n        try:\\n            if not isinstance(run, dict):\\n                continue\\n            metrics = run.get(\\\"metrics\\\", {})\\n            if not isinstance(metrics, dict):\\n                continue\\n            if \\\"latency_ms\\\" not in metrics or \\\"total_tokens\\\" not in metrics:\\n                continue\\n            latency = metrics.get(\\\"latency_ms\\\")\\n            tokens = metrics.get(\\\"total_tokens\\\")\\n            cost = metrics.get(\\\"cost_usd\\\", 0.0)\\n            if not isinstance(latency, (int, float)) or not isinstance(tokens, (int, float)):\\n                continue\\n            if not isinstance(cost, (int, float)):\\n                cost = 0.0\\n            valid_runs.append({\\\"latency_ms\\\": float(latency), \\\"total_tokens\\\": float(tokens), \\\"cost_usd\\\": float(cost)})\\n        except Exception:\\n            continue\\n\\n    if not valid_runs:\\n        return {\\n            \\\"runs_total\\\": 0,\\n            \\\"success_rate\\\": 0.0,\\n            \\\"avg_total_tokens\\\": 0,\\n            \\\"avg_latency_ms\\\": 0,\\n            \\\"total_cost_usd\\\": 0.0,\\n        }\\n\\n    runs_total = len(valid_runs)\\n    success_rate = 100.0\\n    avg_total_tokens = mean(r[\\\"total_tokens\\\"] for r in valid_runs)\\n    avg_latency_ms = mean(r[\\\"latency_ms\\\"] for r in valid_runs)\\n    total_cost_usd = sum(r[\\\"cost_usd\\\"] for r in valid_runs)\\n\\n    return {\\n        \\\"runs_total\\\": runs_total,\\n        \\\"success_rate\\\": success_rate,\\n        \\\"avg_total_tokens\\\": round(avg_total_tokens, 2),\\n        \\\"avg_latency_ms\\\": round(avg_latency_ms, 2),\\n        \\\"total_cost_usd\\\": round(total_cost_usd, 6),\\n    }\"\n    }\n  ],\n  \"dependencies\": {\n    \"dependencies\": {},\n    \"devDependencies\": {}\n  },\n  \"commands\": []\n}\n```"}
